{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3217437-bda0-4646-b4bd-0beea015dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 25\n",
      "Unique half_trip_ids: 13\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n",
      "\n",
      "Created 12 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0      65802629       100     Outbound          welst          elm   \n",
      "1      65802630       100      Inbound            elm        welst   \n",
      "2      65802631       100     Outbound          welst          elm   \n",
      "3      65802632       100      Inbound            elm        welst   \n",
      "4      65802633       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-27 16:00:00 2025-04-27 16:11:00 2025-04-27 16:06:48   \n",
      "1  2025-04-27 16:15:00 2025-04-27 16:27:00 2025-04-27 16:23:13   \n",
      "2  2025-04-27 16:30:00 2025-04-27 16:41:00 2025-04-27 16:38:27   \n",
      "3  2025-04-27 16:45:00 2025-04-27 16:57:00 2025-04-27 16:52:23   \n",
      "4  2025-04-27 17:00:00 2025-04-27 17:11:00 2025-04-27 17:06:23   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-27 16:18:58  \n",
      "1 2025-04-27 16:36:13  \n",
      "2 2025-04-27 16:47:10  \n",
      "3 2025-04-27 17:04:50  \n",
      "4 2025-04-27 17:18:22  \n",
      "\n",
      "Trip nodes saved to route100_trip_nodes.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 90 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id     to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802629     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802630     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802631     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802632     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802633     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_connections.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_99023/4025931758.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_99023/4025931758.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_99023/4025931758.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_99023/4025931758.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arc-flow LP relaxation - Status: Optimal\n",
      "Arc-flow LP relaxation - Objective: 232.63333333333335\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation...\n",
      "Generated 4095 feasible schedules\n",
      "Set partitioning LP relaxation - Status: Optimal\n",
      "Set partitioning LP relaxation - Objective: 232.63333333333333\n",
      "Solution time: 0.10 seconds\n",
      "\n",
      "--- STEP 5: Solving with arc-flow formulation ---\n",
      "Solving MDVSP using arc-flow formulation...\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/helmadevina/Desktop/sklearn-env/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/9704f99a5fa84d53a1c5779b31248600-pulp.mps -sec 300 -timeMode elapsed -branch -printingOptions all -solution /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/9704f99a5fa84d53a1c5779b31248600-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 30 COLUMNS\n",
      "At line 547 RHS\n",
      "At line 573 BOUNDS\n",
      "At line 664 ENDATA\n",
      "Problem MODEL has 25 rows, 90 columns and 246 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 300\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 232.633 - 0.00 seconds\n",
      "Cgl0003I 1 fixed, 0 tightened bounds, 0 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 22 rows, 87 columns (87 integer (87 of which binary)) and 226 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 232.633\n",
      "Cbc0038I Before mini branch and bound, 87 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of 232.633 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 232.63333 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0001I Search completed - best objective 232.63333333332, took 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 232.633 to 232.633\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                232.63333333\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.00\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.02\n",
      "\n",
      "Status: Optimal\n",
      "Total cost: 232.63333333333335\n",
      "Solution time: 0.05 seconds\n",
      "\n",
      "Sample arc-flow solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip         65802629              NaN   \n",
      "2           1         3   trip         65802630              NaN   \n",
      "3           1         4   trip         65802631              NaN   \n",
      "4           1         5   trip         65802632              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-27 16:00:00 2025-04-27 16:11:00   \n",
      "2            elm        welst 2025-04-27 16:15:00 2025-04-27 16:27:00   \n",
      "3          welst          elm 2025-04-27 16:30:00 2025-04-27 16:41:00   \n",
      "4            elm        welst 2025-04-27 16:45:00 2025-04-27 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Arc-flow solution saved to arc_flow_solution.csv\n",
      "\n",
      "--- STEP 6: Solving with set partitioning formulation ---\n",
      "Solving MDVSP using set partitioning formulation...\n",
      "Generating feasible vehicle schedules...\n",
      "Generated 4095 feasible schedules\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/helmadevina/Desktop/sklearn-env/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/9b2b8681ee334192bc82537a26480a68-pulp.mps -sec 300 -timeMode elapsed -branch -printingOptions all -solution /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/9b2b8681ee334192bc82537a26480a68-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 18 COLUMNS\n",
      "At line 40975 RHS\n",
      "At line 40989 BOUNDS\n",
      "At line 45085 ENDATA\n",
      "Problem MODEL has 13 rows, 4095 columns and 28671 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 300\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 232.633 - 0.00 seconds\n",
      "Cgl0004I processed model has 13 rows, 4095 columns (4095 integer (4095 of which binary)) and 28671 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 232.633\n",
      "Cbc0038I Before mini branch and bound, 4095 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.04 seconds)\n",
      "Cbc0038I After 0.04 seconds - Feasibility pump exiting with objective of 232.633 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 232.63333 found by feasibility pump after 0 iterations and 0 nodes (0.04 seconds)\n",
      "Cbc0001I Search completed - best objective 232.6333333333, took 0 iterations and 0 nodes (0.04 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 232.633 to 232.633\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                232.63333333\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.03\n",
      "Time (Wallclock seconds):       0.04\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.05   (Wallclock seconds):       0.05\n",
      "\n",
      "Status: Optimal\n",
      "Total cost: 232.63333333333333\n",
      "Solution time: 0.25 seconds\n",
      "\n",
      "Sample set partitioning solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip         65802629              NaN   \n",
      "2           1         3   trip         65802630              NaN   \n",
      "3           1         4   trip         65802631              NaN   \n",
      "4           1         5   trip         65802632              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-27 16:00:00 2025-04-27 16:11:00   \n",
      "2            elm        welst 2025-04-27 16:15:00 2025-04-27 16:27:00   \n",
      "3          welst          elm 2025-04-27 16:30:00 2025-04-27 16:41:00   \n",
      "4            elm        welst 2025-04-27 16:45:00 2025-04-27 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Set partitioning solution saved to set_partitioning_solution.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pulp as pl\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_ArcFlow\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        for to_id in connections.get(depot_id, {}):\n",
    "            if pl.value(x[(depot_id, to_id)]) > 0.5:  # If this connection is used\n",
    "                # Start a new vehicle schedule\n",
    "                schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                \n",
    "                # Follow the path of this vehicle\n",
    "                current_id = to_id\n",
    "                while current_id != depot_id:\n",
    "                    # Add this trip to the schedule\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                    schedule.append({\n",
    "                        'type': 'trip',\n",
    "                        'id': current_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                    \n",
    "                    # Find the next trip/depot\n",
    "                    next_id = None\n",
    "                    for possible_next in connections.get(current_id, {}):\n",
    "                        if pl.value(x[(current_id, possible_next)]) > 0.5:\n",
    "                            next_id = possible_next\n",
    "                            break\n",
    "                    \n",
    "                    if next_id is None:\n",
    "                        print(f\"Warning: No next trip found for {current_id}\")\n",
    "                        break\n",
    "                        \n",
    "                    current_id = next_id\n",
    "                \n",
    "                # Close the schedule with return to depot\n",
    "                schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                \n",
    "                # Add this schedule to the list\n",
    "                vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if pl.value(y[i]) > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Set partitioning LP relaxation - Objective: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation...\")\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model for arc-flow\n",
    "    arc_flow_model = pl.LpProblem(\"MDVSP_ArcFlow_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    arc_flow_model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        arc_flow_model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        arc_flow_model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    arc_flow_model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    arc_flow_model.solve(solver)\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {pl.LpStatus[arc_flow_model.status]}\")\n",
    "    print(f\"Arc-flow LP relaxation - Objective: {pl.value(arc_flow_model.objective)}\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_4pm_7pm.csv'\n",
    "    trip_nodes_output = 'route100_trip_nodes.csv'\n",
    "    connections_output = 'route100_connections.csv'\n",
    "    arc_flow_solution_output = 'arc_flow_solution.csv'\n",
    "    set_partitioning_solution_output = 'set_partitioning_solution.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964bef54-4a27-4887-9d6f-9ab748e642a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as filtered_route100_8h_20h.csv\n",
      "File saved as filtered_route100_12h_20h.csv\n",
      "File saved as filtered_route100_15h_20h.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_100_clean = pd.read_csv('route 100 clean.csv')\n",
    "df_100_clean_25jan = df_100_clean[df_100_clean['service_date'].str.contains('2025-01-25')]\n",
    "\n",
    "def filter_and_export_by_time(df, start_hour, end_hour):\n",
    "    # Make a copy to avoid modifying original df\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Convert 'scheduled' and 'actual' to datetime if not already\n",
    "    df_filtered['scheduled'] = pd.to_datetime(df_filtered['scheduled'])\n",
    "    df_filtered['actual'] = pd.to_datetime(df_filtered['actual'])\n",
    "\n",
    "    # Filter based on the scheduled hour\n",
    "    df_filtered = df_filtered[\n",
    "        (df_filtered['scheduled'].dt.hour >= start_hour) &\n",
    "        (df_filtered['scheduled'].dt.hour <= end_hour)\n",
    "    ]\n",
    "\n",
    "    # Format 'scheduled' and 'actual' to HH:MM:SS\n",
    "    df_filtered['scheduled'] = df_filtered['scheduled'].dt.strftime('%H:%M:%S')\n",
    "    df_filtered['actual'] = df_filtered['actual'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "    # Define output filename\n",
    "    filename = f\"filtered_route100_{start_hour}h_{end_hour}h.csv\"\n",
    "\n",
    "    # Export to CSV\n",
    "    df_filtered.to_csv(filename, index=False)\n",
    "    print(f\"File saved as {filename}\")\n",
    "\n",
    "    # Return the filtered dataframe\n",
    "    return df_filtered\n",
    "\n",
    "# Filter between 8am and 8pm\n",
    "df_100_8am_8pm = filter_and_export_by_time(df_100_clean_25jan, 8, 20)\n",
    "df_100_12pm_8pm = filter_and_export_by_time(df_100_clean_25jan, 12, 20)\n",
    "df_100_3pm_8pm = filter_and_export_by_time(df_100_clean_25jan, 15, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f164c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env-aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
