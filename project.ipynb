{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa51dc18-5ffd-4340-9acf-687dff3cf939",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Filtering the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964bef54-4a27-4887-9d6f-9ab748e642a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as filtered_route100_16h_20h.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_100_clean = pd.read_csv('route 100 clean.csv')\n",
    "df_100_clean_25jan = df_100_clean[df_100_clean['service_date'].str.contains('2025-01-25')]\n",
    "\n",
    "def filter_and_export_by_time(df, start_hour, end_hour):\n",
    "    # Make a copy to avoid modifying original df\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Convert 'scheduled' and 'actual' to datetime if not already\n",
    "    df_filtered['scheduled'] = pd.to_datetime(df_filtered['scheduled'])\n",
    "    df_filtered['actual'] = pd.to_datetime(df_filtered['actual'])\n",
    "\n",
    "    # Filter based on the scheduled hour\n",
    "    df_filtered = df_filtered[\n",
    "        (df_filtered['scheduled'].dt.hour >= start_hour) &\n",
    "        (df_filtered['scheduled'].dt.hour <= end_hour)\n",
    "    ]\n",
    "\n",
    "    # Format 'scheduled' and 'actual' to HH:MM:SS\n",
    "    df_filtered['scheduled'] = df_filtered['scheduled'].dt.strftime('%H:%M:%S')\n",
    "    df_filtered['actual'] = df_filtered['actual'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "    # Define output filename\n",
    "    filename = f\"filtered_route100_{start_hour}h_{end_hour}h.csv\"\n",
    "\n",
    "    # Export to CSV\n",
    "    df_filtered.to_csv(filename, index=False)\n",
    "    print(f\"File saved as {filename}\")\n",
    "\n",
    "    # Return the filtered dataframe\n",
    "    return df_filtered\n",
    "\n",
    "# Filter between 8am and 8pm\n",
    "#df_100_8am_8pm = filter_and_export_by_time(df_100_clean_25jan, 8, 20)\n",
    "#df_100_12pm_8pm = filter_and_export_by_time(df_100_clean_25jan, 12, 20)\n",
    "df_100_4pm_8pm = filter_and_export_by_time(df_100_clean_25jan, 16, 20)\n",
    "#df_100_3pm_8pm = filter_and_export_by_time(df_100_clean_25jan, 15, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6457233-afd0-4ac1-9d57-3c560f5a6e37",
   "metadata": {},
   "source": [
    "# 1. Using PuLP solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03067d83-3b9f-4b70-92de-43016a9b0ecb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## a. 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3217437-bda0-4646-b4bd-0beea015dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 25\n",
      "Unique half_trip_ids: 13\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n",
      "\n",
      "Created 12 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0      65802629       100     Outbound          welst          elm   \n",
      "1      65802630       100      Inbound            elm        welst   \n",
      "2      65802631       100     Outbound          welst          elm   \n",
      "3      65802632       100      Inbound            elm        welst   \n",
      "4      65802633       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-29 16:00:00 2025-04-29 16:11:00 2025-04-29 16:06:48   \n",
      "1  2025-04-29 16:15:00 2025-04-29 16:27:00 2025-04-29 16:23:13   \n",
      "2  2025-04-29 16:30:00 2025-04-29 16:41:00 2025-04-29 16:38:27   \n",
      "3  2025-04-29 16:45:00 2025-04-29 16:57:00 2025-04-29 16:52:23   \n",
      "4  2025-04-29 17:00:00 2025-04-29 17:11:00 2025-04-29 17:06:23   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-29 16:18:58  \n",
      "1 2025-04-29 16:36:13  \n",
      "2 2025-04-29 16:47:10  \n",
      "3 2025-04-29 17:04:50  \n",
      "4 2025-04-29 17:18:22  \n",
      "\n",
      "Trip nodes saved to route100_4h_7h_trip_nodes_pulp.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 90 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id     to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802629     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802630     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802631     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802632     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802633     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_4h_7h_connections_pulp.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/4054497762.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/4054497762.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/4054497762.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/4054497762.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arc-flow LP relaxation - Status: Optimal\n",
      "Arc-flow LP relaxation - Objective: 232.63333333333335\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation...\n",
      "Generated 4095 feasible schedules\n",
      "Set partitioning LP relaxation - Status: Optimal\n",
      "Set partitioning LP relaxation - Objective: 232.63333333333333\n",
      "Solution time: 0.09 seconds\n",
      "\n",
      "--- STEP 5: Solving with arc-flow formulation ---\n",
      "Solving MDVSP using arc-flow formulation...\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/helmadevina/Desktop/sklearn-env/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/e6768e3b14f4451cb96ab10e334d85d2-pulp.mps -sec 300 -timeMode elapsed -branch -printingOptions all -solution /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/e6768e3b14f4451cb96ab10e334d85d2-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 30 COLUMNS\n",
      "At line 547 RHS\n",
      "At line 573 BOUNDS\n",
      "At line 664 ENDATA\n",
      "Problem MODEL has 25 rows, 90 columns and 246 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 300\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 232.633 - 0.00 seconds\n",
      "Cgl0003I 1 fixed, 0 tightened bounds, 0 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 22 rows, 87 columns (87 integer (87 of which binary)) and 226 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 232.633\n",
      "Cbc0038I Before mini branch and bound, 87 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.02 seconds)\n",
      "Cbc0038I After 0.02 seconds - Feasibility pump exiting with objective of 232.633 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 232.63333 found by feasibility pump after 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0001I Search completed - best objective 232.63333333332, took 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 232.633 to 232.633\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                232.63333333\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.00\n",
      "Time (Wallclock seconds):       0.02\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.02\n",
      "\n",
      "Status: Optimal\n",
      "Total cost: 232.63333333333335\n",
      "Solution time: 0.03 seconds\n",
      "\n",
      "Sample arc-flow solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip         65802629              NaN   \n",
      "2           1         3   trip         65802630              NaN   \n",
      "3           1         4   trip         65802631              NaN   \n",
      "4           1         5   trip         65802632              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Arc-flow solution saved to route100_4h_7h_arc_flow_solution_pulp.csv\n",
      "\n",
      "--- STEP 6: Solving with set partitioning formulation ---\n",
      "Solving MDVSP using set partitioning formulation...\n",
      "Generating feasible vehicle schedules...\n",
      "Generated 4095 feasible schedules\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/helmadevina/Desktop/sklearn-env/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/22b641f4e5684064a834143da579e9cf-pulp.mps -sec 300 -timeMode elapsed -branch -printingOptions all -solution /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/22b641f4e5684064a834143da579e9cf-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 18 COLUMNS\n",
      "At line 40975 RHS\n",
      "At line 40989 BOUNDS\n",
      "At line 45085 ENDATA\n",
      "Problem MODEL has 13 rows, 4095 columns and 28671 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 300\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 232.633 - 0.00 seconds\n",
      "Cgl0004I processed model has 13 rows, 4095 columns (4095 integer (4095 of which binary)) and 28671 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 232.633\n",
      "Cbc0038I Before mini branch and bound, 4095 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.03 seconds)\n",
      "Cbc0038I After 0.03 seconds - Feasibility pump exiting with objective of 232.633 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 232.63333 found by feasibility pump after 0 iterations and 0 nodes (0.03 seconds)\n",
      "Cbc0001I Search completed - best objective 232.6333333333, took 0 iterations and 0 nodes (0.03 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 232.633 to 232.633\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                232.63333333\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.03\n",
      "Time (Wallclock seconds):       0.04\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.05   (Wallclock seconds):       0.05\n",
      "\n",
      "Status: Optimal\n",
      "Total cost: 232.63333333333333\n",
      "Solution time: 0.14 seconds\n",
      "\n",
      "Sample set partitioning solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip         65802629              NaN   \n",
      "2           1         3   trip         65802630              NaN   \n",
      "3           1         4   trip         65802631              NaN   \n",
      "4           1         5   trip         65802632              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Set partitioning solution saved to route100_4h_7h_set_partitioning_solution_pulp.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pulp as pl\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_ArcFlow\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        for to_id in connections.get(depot_id, {}):\n",
    "            if pl.value(x[(depot_id, to_id)]) > 0.5:  # If this connection is used\n",
    "                # Start a new vehicle schedule\n",
    "                schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                \n",
    "                # Follow the path of this vehicle\n",
    "                current_id = to_id\n",
    "                while current_id != depot_id:\n",
    "                    # Add this trip to the schedule\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                    schedule.append({\n",
    "                        'type': 'trip',\n",
    "                        'id': current_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                    \n",
    "                    # Find the next trip/depot\n",
    "                    next_id = None\n",
    "                    for possible_next in connections.get(current_id, {}):\n",
    "                        if pl.value(x[(current_id, possible_next)]) > 0.5:\n",
    "                            next_id = possible_next\n",
    "                            break\n",
    "                    \n",
    "                    if next_id is None:\n",
    "                        print(f\"Warning: No next trip found for {current_id}\")\n",
    "                        break\n",
    "                        \n",
    "                    current_id = next_id\n",
    "                \n",
    "                # Close the schedule with return to depot\n",
    "                schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                \n",
    "                # Add this schedule to the list\n",
    "                vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if pl.value(y[i]) > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Set partitioning LP relaxation - Objective: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation...\")\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model for arc-flow\n",
    "    arc_flow_model = pl.LpProblem(\"MDVSP_ArcFlow_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    arc_flow_model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        arc_flow_model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        arc_flow_model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    arc_flow_model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    arc_flow_model.solve(solver)\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {pl.LpStatus[arc_flow_model.status]}\")\n",
    "    print(f\"Arc-flow LP relaxation - Objective: {pl.value(arc_flow_model.objective)}\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_4h_7h.csv'\n",
    "    trip_nodes_output = 'route100_4h_7h_trip_nodes_pulp.csv'\n",
    "    connections_output = 'route100_4h_7h_connections_pulp.csv'\n",
    "    arc_flow_solution_output = 'route100_4h_7h_arc_flow_solution_pulp.csv'\n",
    "    set_partitioning_solution_output = 'route100_4h_7h_set_partitioning_solution_pulp.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e197c1-19ff-479e-ad76-03bda3e7ec7e",
   "metadata": {},
   "source": [
    "## b. 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c6c329-1078-4d7e-91ad-18677a767e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 40\n",
      "Unique half_trip_ids: 20\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n",
      "\n",
      "Created 20 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0    65802629.0       100     Outbound          welst          elm   \n",
      "1    65802630.0       100      Inbound            elm        welst   \n",
      "2    65802631.0       100     Outbound          welst          elm   \n",
      "3    65802632.0       100      Inbound            elm        welst   \n",
      "4    65802633.0       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-29 16:00:00 2025-04-29 16:11:00 2025-04-29 16:06:48   \n",
      "1  2025-04-29 16:15:00 2025-04-29 16:27:00 2025-04-29 16:23:13   \n",
      "2  2025-04-29 16:30:00 2025-04-29 16:41:00 2025-04-29 16:38:27   \n",
      "3  2025-04-29 16:45:00 2025-04-29 16:57:00 2025-04-29 16:52:23   \n",
      "4  2025-04-29 17:00:00 2025-04-29 17:11:00 2025-04-29 17:06:23   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-29 16:18:58  \n",
      "1 2025-04-29 16:36:13  \n",
      "2 2025-04-29 16:47:10  \n",
      "3 2025-04-29 17:04:50  \n",
      "4 2025-04-29 17:18:22  \n",
      "\n",
      "Trip nodes saved to route100_16h_20h_trip_nodes_pulp.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 230 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id       to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802629.0     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802630.0     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802631.0     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802632.0     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802633.0     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_16h_20h_connections_pulp.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation...\n",
      "Arc-flow LP relaxation - Status: Optimal\n",
      "Arc-flow LP relaxation - Objective: 313.1666666666667\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/3865941237.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/3865941237.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/3865941237.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/3865941237.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1048575 feasible schedules\n",
      "Set partitioning LP relaxation - Status: Optimal\n",
      "Set partitioning LP relaxation - Objective: 313.16666666666663\n",
      "Solution time: 47.85 seconds\n",
      "\n",
      "--- STEP 5: Solving with arc-flow formulation ---\n",
      "Solving MDVSP using arc-flow formulation...\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/helmadevina/Desktop/sklearn-env/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ab5942461017435c9fae5a8b90c06f2f-pulp.mps -sec 300 -timeMode elapsed -branch -printingOptions all -solution /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ab5942461017435c9fae5a8b90c06f2f-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 46 COLUMNS\n",
      "At line 1387 RHS\n",
      "At line 1429 BOUNDS\n",
      "At line 1660 ENDATA\n",
      "Problem MODEL has 41 rows, 230 columns and 650 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 300\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 313.167 - 0.00 seconds\n",
      "Cgl0003I 1 fixed, 0 tightened bounds, 0 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 38 rows, 227 columns (227 integer (227 of which binary)) and 622 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 313.167\n",
      "Cbc0038I Before mini branch and bound, 227 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of 313.167 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 313.16667 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0001I Search completed - best objective 313.16666666665, took 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 313.167 to 313.167\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                313.16666667\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.00\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.02\n",
      "\n",
      "Status: Optimal\n",
      "Total cost: 313.1666666666667\n",
      "Solution time: 0.08 seconds\n",
      "\n",
      "Sample arc-flow solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip       65802629.0              NaN   \n",
      "2           1         3   trip       65802630.0              NaN   \n",
      "3           1         4   trip       65802631.0              NaN   \n",
      "4           1         5   trip       65802632.0              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Arc-flow solution saved to route100_16h_20h_arc_flow_solution_pulp.csv\n",
      "\n",
      "--- STEP 6: Solving with set partitioning formulation ---\n",
      "Solving MDVSP using set partitioning formulation...\n",
      "Generating feasible vehicle schedules...\n",
      "Generated 1048575 feasible schedules\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/helmadevina/Desktop/sklearn-env/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/3891d7d2c5344ed8845568f2e7440569-pulp.mps -sec 300 -timeMode elapsed -branch -printingOptions all -solution /var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/3891d7d2c5344ed8845568f2e7440569-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 26 COLUMNS\n",
      "At line 14680087 RHS\n",
      "At line 14680109 BOUNDS\n",
      "At line 15728685 ENDATA\n",
      "Problem MODEL has 21 rows, 1048575 columns and 11534335 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 300\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 313.167 - 1.46 seconds\n",
      "Cgl0004I processed model has 21 rows, 1048575 columns (1048575 integer (1048575 of which binary)) and 11534335 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of 313.167\n",
      "Cbc0038I Before mini branch and bound, 1048575 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (18.65 seconds)\n",
      "Cbc0038I After 18.68 seconds - Feasibility pump exiting with objective of 313.167 - took 1.39 seconds\n",
      "Cbc0012I Integer solution of 313.16667 found by feasibility pump after 0 iterations and 0 nodes (18.90 seconds)\n",
      "Cbc0001I Search completed - best objective 313.1666666666, took 0 iterations and 0 nodes (19.86 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 313.167 to 313.167\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                313.16666667\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             13.13\n",
      "Time (Wallclock seconds):       22.81\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       16.93   (Wallclock seconds):       26.95\n",
      "\n",
      "Status: Optimal\n",
      "Total cost: 313.16666666666663\n",
      "Solution time: 68.71 seconds\n",
      "\n",
      "Sample set partitioning solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip       65802629.0              NaN   \n",
      "2           1         3   trip       65802630.0              NaN   \n",
      "3           1         4   trip       65802631.0              NaN   \n",
      "4           1         5   trip       65802632.0              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Set partitioning solution saved to route100_16h_20h_set_partitioning_solution_pulp.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pulp as pl\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_ArcFlow\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        for to_id in connections.get(depot_id, {}):\n",
    "            if pl.value(x[(depot_id, to_id)]) > 0.5:  # If this connection is used\n",
    "                # Start a new vehicle schedule\n",
    "                schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                \n",
    "                # Follow the path of this vehicle\n",
    "                current_id = to_id\n",
    "                while current_id != depot_id:\n",
    "                    # Add this trip to the schedule\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                    schedule.append({\n",
    "                        'type': 'trip',\n",
    "                        'id': current_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                    \n",
    "                    # Find the next trip/depot\n",
    "                    next_id = None\n",
    "                    for possible_next in connections.get(current_id, {}):\n",
    "                        if pl.value(x[(current_id, possible_next)]) > 0.5:\n",
    "                            next_id = possible_next\n",
    "                            break\n",
    "                    \n",
    "                    if next_id is None:\n",
    "                        print(f\"Warning: No next trip found for {current_id}\")\n",
    "                        break\n",
    "                        \n",
    "                    current_id = next_id\n",
    "                \n",
    "                # Close the schedule with return to depot\n",
    "                schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                \n",
    "                # Add this schedule to the list\n",
    "                vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if pl.value(y[i]) > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Set partitioning LP relaxation - Objective: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation...\")\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model for arc-flow\n",
    "    arc_flow_model = pl.LpProblem(\"MDVSP_ArcFlow_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    arc_flow_model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        arc_flow_model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        arc_flow_model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    arc_flow_model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    arc_flow_model.solve(solver)\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {pl.LpStatus[arc_flow_model.status]}\")\n",
    "    print(f\"Arc-flow LP relaxation - Objective: {pl.value(arc_flow_model.objective)}\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_16h_20h.csv'\n",
    "    trip_nodes_output = 'route100_16h_20h_trip_nodes_pulp.csv'\n",
    "    connections_output = 'route100_16h_20h_connections_pulp.csv'\n",
    "    arc_flow_solution_output = 'route100_16h_20h_arc_flow_solution_pulp.csv'\n",
    "    set_partitioning_solution_output = 'route100_16h_20h_set_partitioning_solution_pulp.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22996c9b-0efe-4360-9497-0b67b273e3d7",
   "metadata": {},
   "source": [
    "## c. 5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee74bc-18f6-443d-987e-00abbd73b34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 48\n",
      "Unique half_trip_ids: 24\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n",
      "\n",
      "Created 24 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0    65802625.0       100     Outbound          welst          elm   \n",
      "1    65802626.0       100      Inbound            elm        welst   \n",
      "2    65802627.0       100     Outbound          welst          elm   \n",
      "3    65802628.0       100      Inbound            elm        welst   \n",
      "4    65802629.0       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-29 15:00:00 2025-04-29 15:11:00 2025-04-29 15:06:11   \n",
      "1  2025-04-29 15:15:00 2025-04-29 15:26:00 2025-04-29 15:24:30   \n",
      "2  2025-04-29 15:30:00 2025-04-29 15:41:00 2025-04-29 15:38:30   \n",
      "3  2025-04-29 15:45:00 2025-04-29 15:57:00 2025-04-29 15:48:49   \n",
      "4  2025-04-29 16:00:00 2025-04-29 16:11:00 2025-04-29 16:06:48   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-29 15:18:05  \n",
      "1 2025-04-29 15:36:31  \n",
      "2 2025-04-29 15:48:10  \n",
      "3 2025-04-29 16:00:03  \n",
      "4 2025-04-29 16:18:58  \n",
      "\n",
      "Trip nodes saved to route100_15h_20h_trip_nodes.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 324 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id       to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802625.0     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802626.0     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802627.0     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802628.0     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802629.0     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_15h_20h_connections.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_18434/2398953751.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_18434/2398953751.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_18434/2398953751.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_18434/2398953751.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arc-flow LP relaxation - Status: Optimal\n",
      "Arc-flow LP relaxation - Objective: 378.29999999999995\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation...\n",
      "Generated 16777215 feasible schedules\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pulp as pl\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_ArcFlow\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        for to_id in connections.get(depot_id, {}):\n",
    "            if pl.value(x[(depot_id, to_id)]) > 0.5:  # If this connection is used\n",
    "                # Start a new vehicle schedule\n",
    "                schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                \n",
    "                # Follow the path of this vehicle\n",
    "                current_id = to_id\n",
    "                while current_id != depot_id:\n",
    "                    # Add this trip to the schedule\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                    schedule.append({\n",
    "                        'type': 'trip',\n",
    "                        'id': current_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                    \n",
    "                    # Find the next trip/depot\n",
    "                    next_id = None\n",
    "                    for possible_next in connections.get(current_id, {}):\n",
    "                        if pl.value(x[(current_id, possible_next)]) > 0.5:\n",
    "                            next_id = possible_next\n",
    "                            break\n",
    "                    \n",
    "                    if next_id is None:\n",
    "                        print(f\"Warning: No next trip found for {current_id}\")\n",
    "                        break\n",
    "                        \n",
    "                    current_id = next_id\n",
    "                \n",
    "                # Close the schedule with return to depot\n",
    "                schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                \n",
    "                # Add this schedule to the list\n",
    "                vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning\", pl.LpMinimize)\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", cat='Binary')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the model\n",
    "    solver = pl.PULP_CBC_CMD(msg=True, timeLimit=300)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Total cost: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == pl.LpStatusOptimal:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if pl.value(y[i]) > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the PuLP model\n",
    "    model = pl.LpProblem(\"MDVSP_SetPartitioning_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = pl.LpVariable(f\"y_{i}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    model += pl.lpSum([y[i] * schedule['cost'] for i, schedule in enumerate(feasible_schedules)])\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        model += pl.lpSum([y[i] for i, schedule in enumerate(feasible_schedules) if trip in schedule['trips']]) == 1, f\"Trip_{trip}_must_be_served\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    model += pl.lpSum([y[i] for i in range(len(feasible_schedules))]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    model.solve(solver)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {pl.LpStatus[model.status]}\")\n",
    "    print(f\"Set partitioning LP relaxation - Objective: {pl.value(model.objective)}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation...\")\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the PuLP model for arc-flow\n",
    "    arc_flow_model = pl.LpProblem(\"MDVSP_ArcFlow_LP\", pl.LpMinimize)\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = pl.LpVariable(f\"x_{from_id}_{to_id}\", lowBound=0, upBound=1, cat='Continuous')\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    arc_flow_model += pl.lpSum([x[(conn['from_id'], conn['to_id'])] * conn['total_cost'] for _, conn in connections_df.iterrows()])\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = pl.lpSum([x[(from_id, trip)] for from_id in connections if trip in connections[from_id]])\n",
    "        outflow = pl.lpSum([x[(trip, to_id)] for to_id in connections.get(trip, {})])\n",
    "        \n",
    "        arc_flow_model += inflow == 1, f\"Trip_{trip}_must_be_served\"\n",
    "        arc_flow_model += inflow == outflow, f\"Flow_conservation_{trip}\"\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    arc_flow_model += pl.lpSum([x[(depot_id, to_id)] for to_id in connections.get(depot_id, {})]) <= max_vehicles, \"Max_vehicles\"\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    solver = pl.PULP_CBC_CMD(msg=False)\n",
    "    arc_flow_model.solve(solver)\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {pl.LpStatus[arc_flow_model.status]}\")\n",
    "    print(f\"Arc-flow LP relaxation - Objective: {pl.value(arc_flow_model.objective)}\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_15h_20h.csv'\n",
    "    trip_nodes_output = 'route100_15h_20h_trip_nodes_pulp.csv'\n",
    "    connections_output = 'route100_15h_20h_connections_pulp.csv'\n",
    "    arc_flow_solution_output = 'route100_15h_20h_arc_flow_solution_pulp.csv'\n",
    "    set_partitioning_solution_output = 'route100_15h_20h_set_partitioning_solution_pulp.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ab1c3-e40d-4aec-a987-348d7557ba8f",
   "metadata": {},
   "source": [
    "# 2. Using Gurobi for multiple time slot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d458f0-d304-43d5-8680-e8f27bb7af3f",
   "metadata": {},
   "source": [
    "## a. 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bec5f29-9e93-4ff4-82b6-b3213db7dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 25\n",
      "Unique half_trip_ids: 13\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n",
      "\n",
      "Created 12 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0      65802629       100     Outbound          welst          elm   \n",
      "1      65802630       100      Inbound            elm        welst   \n",
      "2      65802631       100     Outbound          welst          elm   \n",
      "3      65802632       100      Inbound            elm        welst   \n",
      "4      65802633       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-29 16:00:00 2025-04-29 16:11:00 2025-04-29 16:06:48   \n",
      "1  2025-04-29 16:15:00 2025-04-29 16:27:00 2025-04-29 16:23:13   \n",
      "2  2025-04-29 16:30:00 2025-04-29 16:41:00 2025-04-29 16:38:27   \n",
      "3  2025-04-29 16:45:00 2025-04-29 16:57:00 2025-04-29 16:52:23   \n",
      "4  2025-04-29 17:00:00 2025-04-29 17:11:00 2025-04-29 17:06:23   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-29 16:18:58  \n",
      "1 2025-04-29 16:36:13  \n",
      "2 2025-04-29 16:47:10  \n",
      "3 2025-04-29 17:04:50  \n",
      "4 2025-04-29 17:18:22  \n",
      "\n",
      "Trip nodes saved to route100_4h_7h_trip_nodes_gurobi.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 90 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id     to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802629     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802630     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802631     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802632     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802633     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_4h_7h_connections_gurobi.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation with Gurobi...\n",
      "Arc-flow LP relaxation - Status: 2\n",
      "Arc-flow LP relaxation - Objective: 232.63333333333335\n",
      "Solution time: 0.02 seconds\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation with Gurobi...\n",
      "Generated 4095 feasible schedules\n",
      "Set partitioning LP relaxation - Status: 2\n",
      "Set partitioning LP relaxation - Objective: 232.63333333333333\n",
      "Solution time: 0.03 seconds\n",
      "\n",
      "--- STEP 5: Solving with arc-flow formulation ---\n",
      "Solving MDVSP using arc-flow formulation with Gurobi...\n",
      "Set parameter TimeLimit to value 300\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 25 rows, 90 columns and 246 nonzeros\n",
      "Model fingerprint: 0x2431560b\n",
      "Variable types: 0 continuous, 90 integer (90 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+01, 9e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 339.6333333\n",
      "Presolve removed 25 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 232.633 339.633 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.326333333333e+02, best bound 2.326333333333e+02, gap 0.0000%\n",
      "Status: 2\n",
      "Total cost: 232.63333333333335\n",
      "Solution time: 0.01 seconds\n",
      "\n",
      "Sample arc-flow solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip         65802629              NaN   \n",
      "2           1         3   trip         65802630              NaN   \n",
      "3           1         4   trip         65802631              NaN   \n",
      "4           1         5   trip         65802632              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Arc-flow solution saved to route100_4h_7h_arc_flow_solution_gurobi.csv\n",
      "\n",
      "--- STEP 6: Solving with set partitioning formulation ---\n",
      "Solving MDVSP using set partitioning formulation with Gurobi...\n",
      "Generating feasible vehicle schedules...\n",
      "Generated 4095 feasible schedules\n",
      "Set parameter TimeLimit to value 300\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 13 rows, 4095 columns and 28671 nonzeros\n",
      "Model fingerprint: 0x37226110\n",
      "Variable types: 0 continuous, 4095 integer (4095 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [3e+01, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Presolve time: 0.02s\n",
      "Presolved: 13 rows, 4095 columns, 26623 nonzeros\n",
      "Variable types: 0 continuous, 4095 integer (4095 binary)\n",
      "Found heuristic solution: objective 238.7666667\n",
      "\n",
      "Root relaxation: objective 2.326333e+02, 12 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     232.6333333  232.63333  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (12 simplex iterations) in 0.04 seconds (0.05 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 232.633 238.767 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.326333333333e+02, best bound 2.326333333333e+02, gap 0.0000%\n",
      "Status: 2\n",
      "Total cost: 232.63333333333333\n",
      "Solution time: 0.06 seconds\n",
      "\n",
      "Sample set partitioning solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip         65802629              NaN   \n",
      "2           1         3   trip         65802630              NaN   \n",
      "3           1         4   trip         65802631              NaN   \n",
      "4           1         5   trip         65802632              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Set partitioning solution saved to route100_4h_7h_set_partitioning_solution_gurobi.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/2576639542.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/2576639542.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/2576639542.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/2576639542.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation with Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_ArcFlow\")\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = model.addVar(vtype=GRB.BINARY, name=f\"x_{from_id}_{to_id}\")\n",
    "    \n",
    "    # Update the model to include new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        obj += x[(from_id, to_id)] * conn['total_cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = gp.LinExpr()\n",
    "        outflow = gp.LinExpr()\n",
    "        \n",
    "        for from_id in connections:\n",
    "            if trip in connections[from_id]:\n",
    "                inflow += x[(from_id, trip)]\n",
    "        \n",
    "        if trip in connections:\n",
    "            for to_id in connections[trip]:\n",
    "                outflow += x[(trip, to_id)]\n",
    "        \n",
    "        model.addConstr(inflow == 1, f\"Trip_{trip}_must_be_served\")\n",
    "        model.addConstr(inflow == outflow, f\"Flow_conservation_{trip}\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    outflow_from_depot = gp.LinExpr()\n",
    "    if depot_id in connections:\n",
    "        for to_id in connections[depot_id]:\n",
    "            outflow_from_depot += x[(depot_id, to_id)]\n",
    "    \n",
    "    model.addConstr(outflow_from_depot <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set time limit and solver parameters\n",
    "    model.setParam('TimeLimit', 300)  # 5 minutes time limit\n",
    "    model.setParam('OutputFlag', 1)   # Display solver output\n",
    "    \n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        print(f\"Total cost: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        if depot_id in connections:\n",
    "            for to_id in connections[depot_id]:\n",
    "                if x[(depot_id, to_id)].x > 0.5:  # If this connection is used\n",
    "                    # Start a new vehicle schedule\n",
    "                    schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                    \n",
    "                    # Follow the path of this vehicle\n",
    "                    current_id = to_id\n",
    "                    while current_id != depot_id:\n",
    "                        # Add this trip to the schedule\n",
    "                        trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                        schedule.append({\n",
    "                            'type': 'trip',\n",
    "                            'id': current_id,\n",
    "                            'start_location': trip_info['start_location'],\n",
    "                            'end_location': trip_info['end_location'],\n",
    "                            'start_time': trip_info['scheduled_start_time'],\n",
    "                            'end_time': trip_info['scheduled_end_time'],\n",
    "                            'route_id': trip_info['route_id'],\n",
    "                            'direction_id': trip_info['direction_id']\n",
    "                        })\n",
    "                        \n",
    "                        # Find the next trip/depot\n",
    "                        next_id = None\n",
    "                        if current_id in connections:\n",
    "                            for possible_next in connections[current_id]:\n",
    "                                if x[(current_id, possible_next)].x > 0.5:\n",
    "                                    next_id = possible_next\n",
    "                                    break\n",
    "                        \n",
    "                        if next_id is None:\n",
    "                            print(f\"Warning: No next trip found for {current_id}\")\n",
    "                            break\n",
    "                            \n",
    "                        current_id = next_id\n",
    "                    \n",
    "                    # Close the schedule with return to depot\n",
    "                    schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                    \n",
    "                    # Add this schedule to the list\n",
    "                    vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation with Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_SetPartitioning\")\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = model.addVar(vtype=GRB.BINARY, name=f\"y_{i}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        obj += y[i] * schedule['cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        constr = gp.LinExpr()\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if trip in schedule['trips']:\n",
    "                constr += y[i]\n",
    "        model.addConstr(constr == 1, f\"Trip_{trip}_must_be_served\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    vehicles_constr = gp.LinExpr()\n",
    "    for i in range(len(feasible_schedules)):\n",
    "        vehicles_constr += y[i]\n",
    "    model.addConstr(vehicles_constr <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set time limit and solver parameters\n",
    "    model.setParam('TimeLimit', 300)  # 5 minutes time limit\n",
    "    model.setParam('OutputFlag', 1)   # Display solver output\n",
    "    \n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        print(f\"Total cost: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if y[i].x > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation using Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_SetPartitioning_LP\")\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = model.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"y_{i}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        obj += y[i] * schedule['cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        constr = gp.LinExpr()\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if trip in schedule['trips']:\n",
    "                constr += y[i]\n",
    "        model.addConstr(constr == 1, f\"Trip_{trip}_must_be_served\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    vehicles_constr = gp.LinExpr()\n",
    "    for i in range(len(feasible_schedules)):\n",
    "        vehicles_constr += y[i]\n",
    "    model.addConstr(vehicles_constr <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set solver parameters\n",
    "    model.setParam('OutputFlag', 0)  # Suppress solver output\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        print(f\"Set partitioning LP relaxation - Objective: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation using Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the Gurobi model for arc-flow\n",
    "    model = gp.Model(\"MDVSP_ArcFlow_LP\")\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = model.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"x_{from_id}_{to_id}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        obj += x[(from_id, to_id)] * conn['total_cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = gp.LinExpr()\n",
    "        outflow = gp.LinExpr()\n",
    "        \n",
    "        for from_id in connections:\n",
    "            if trip in connections[from_id]:\n",
    "                inflow += x[(from_id, trip)]\n",
    "        \n",
    "        if trip in connections:\n",
    "            for to_id in connections[trip]:\n",
    "                outflow += x[(trip, to_id)]\n",
    "        \n",
    "        model.addConstr(inflow == 1, f\"Trip_{trip}_must_be_served\")\n",
    "        model.addConstr(inflow == outflow, f\"Flow_conservation_{trip}\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    outflow_from_depot = gp.LinExpr()\n",
    "    if depot_id in connections:\n",
    "        for to_id in connections[depot_id]:\n",
    "            outflow_from_depot += x[(depot_id, to_id)]\n",
    "    \n",
    "    model.addConstr(outflow_from_depot <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set solver parameters\n",
    "    model.setParam('OutputFlag', 0)  # Suppress solver output\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        print(f\"Arc-flow LP relaxation - Objective: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_4h_7h.csv'\n",
    "    trip_nodes_output = 'route100_4h_7h_trip_nodes_gurobi.csv'\n",
    "    connections_output = 'route100_4h_7h_connections_gurobi.csv'\n",
    "    arc_flow_solution_output = 'route100_4h_7h_arc_flow_solution_gurobi.csv'\n",
    "    set_partitioning_solution_output = 'route100_4h_7h_set_partitioning_solution_gurobi.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9a598-1201-4c23-a6b1-7d31da453c52",
   "metadata": {},
   "source": [
    "## b. 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6436bdbd-897a-4885-b836-7885d2f46f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 40\n",
      "Unique half_trip_ids: 20\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/16876758.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/16876758.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/16876758.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_21153/16876758.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 20 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0    65802629.0       100     Outbound          welst          elm   \n",
      "1    65802630.0       100      Inbound            elm        welst   \n",
      "2    65802631.0       100     Outbound          welst          elm   \n",
      "3    65802632.0       100      Inbound            elm        welst   \n",
      "4    65802633.0       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-29 16:00:00 2025-04-29 16:11:00 2025-04-29 16:06:48   \n",
      "1  2025-04-29 16:15:00 2025-04-29 16:27:00 2025-04-29 16:23:13   \n",
      "2  2025-04-29 16:30:00 2025-04-29 16:41:00 2025-04-29 16:38:27   \n",
      "3  2025-04-29 16:45:00 2025-04-29 16:57:00 2025-04-29 16:52:23   \n",
      "4  2025-04-29 17:00:00 2025-04-29 17:11:00 2025-04-29 17:06:23   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-29 16:18:58  \n",
      "1 2025-04-29 16:36:13  \n",
      "2 2025-04-29 16:47:10  \n",
      "3 2025-04-29 17:04:50  \n",
      "4 2025-04-29 17:18:22  \n",
      "\n",
      "Trip nodes saved to route100_16h_20h_trip_nodes_gurobi.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 230 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id       to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802629.0     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802630.0     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802631.0     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802632.0     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802633.0     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_16h_20h_connections_gurobi.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation with Gurobi...\n",
      "Arc-flow LP relaxation - Status: 2\n",
      "Arc-flow LP relaxation - Objective: 313.1666666666667\n",
      "Solution time: 0.01 seconds\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation with Gurobi...\n",
      "Generated 1048575 feasible schedules\n",
      "Set partitioning LP relaxation - Status: 2\n",
      "Set partitioning LP relaxation - Objective: 313.16666666666663\n",
      "Solution time: 11.74 seconds\n",
      "\n",
      "--- STEP 5: Solving with arc-flow formulation ---\n",
      "Solving MDVSP using arc-flow formulation with Gurobi...\n",
      "Set parameter TimeLimit to value 300\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 41 rows, 230 columns and 650 nonzeros\n",
      "Model fingerprint: 0x3c622f49\n",
      "Variable types: 0 continuous, 230 integer (230 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [7e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 763.4166667\n",
      "Presolve removed 12 rows and 58 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 29 rows, 172 columns, 326 nonzeros\n",
      "Found heuristic solution: objective 387.6000000\n",
      "Variable types: 0 continuous, 172 integer (172 binary)\n",
      "\n",
      "Root relaxation: objective 3.131667e+02, 20 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     313.1666667  313.16667  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (20 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 313.167 387.6 763.417 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.131666666667e+02, best bound 3.131666666667e+02, gap 0.0000%\n",
      "Status: 2\n",
      "Total cost: 313.1666666666667\n",
      "Solution time: 0.02 seconds\n",
      "\n",
      "Sample arc-flow solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip       65802629.0              NaN   \n",
      "2           1         3   trip       65802630.0              NaN   \n",
      "3           1         4   trip       65802631.0              NaN   \n",
      "4           1         5   trip       65802632.0              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Arc-flow solution saved to route100_16h_20h_arc_flow_solution_gurobi.csv\n",
      "\n",
      "--- STEP 6: Solving with set partitioning formulation ---\n",
      "Solving MDVSP using set partitioning formulation with Gurobi...\n",
      "Generating feasible vehicle schedules...\n",
      "Generated 1048575 feasible schedules\n",
      "Set parameter TimeLimit to value 300\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 21 rows, 1048575 columns and 11534335 nonzeros\n",
      "Model fingerprint: 0x3b87399a\n",
      "Variable types: 0 continuous, 1048575 integer (1048575 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [3e+01, 3e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 5s) ...\n",
      "Presolve time: 7.06s\n",
      "Presolved: 21 rows, 1048575 columns, 11010047 nonzeros\n",
      "Variable types: 0 continuous, 1048575 integer (1048575 binary)\n",
      "Found heuristic solution: objective 319.3000000\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.000000e+01   0.000000e+00     10s\n",
      "\n",
      "Starting sifting (using dual simplex for sub-problems)...\n",
      "\n",
      "    Iter     Pivots    Primal Obj      Dual Obj        Time\n",
      "       0          0     infinity      0.0000000e+00     10s\n",
      "       1         20   3.3223333e+02   3.0263115e+02     10s\n",
      "\n",
      "Sifting complete\n",
      "\n",
      "      43    3.1316667e+02   0.000000e+00   0.000000e+00     10s\n",
      "\n",
      "Root relaxation: objective 3.131667e+02, 43 iterations, 0.44 seconds (0.51 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     313.1666667  313.16667  0.00%     -   10s\n",
      "\n",
      "Explored 1 nodes (43 simplex iterations) in 10.10 seconds (24.31 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 313.167 319.3 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.131666666667e+02, best bound 3.131666666667e+02, gap 0.0000%\n",
      "Status: 2\n",
      "Total cost: 313.16666666666663\n",
      "Solution time: 19.78 seconds\n",
      "\n",
      "Sample set partitioning solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip       65802629.0              NaN   \n",
      "2           1         3   trip       65802630.0              NaN   \n",
      "3           1         4   trip       65802631.0              NaN   \n",
      "4           1         5   trip       65802632.0              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 16:00:00 2025-04-29 16:11:00   \n",
      "2            elm        welst 2025-04-29 16:15:00 2025-04-29 16:27:00   \n",
      "3          welst          elm 2025-04-29 16:30:00 2025-04-29 16:41:00   \n",
      "4            elm        welst 2025-04-29 16:45:00 2025-04-29 16:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Set partitioning solution saved to route100_16h_20h_set_partitioning_solution_gurobi.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation with Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_ArcFlow\")\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = model.addVar(vtype=GRB.BINARY, name=f\"x_{from_id}_{to_id}\")\n",
    "    \n",
    "    # Update the model to include new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        obj += x[(from_id, to_id)] * conn['total_cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = gp.LinExpr()\n",
    "        outflow = gp.LinExpr()\n",
    "        \n",
    "        for from_id in connections:\n",
    "            if trip in connections[from_id]:\n",
    "                inflow += x[(from_id, trip)]\n",
    "        \n",
    "        if trip in connections:\n",
    "            for to_id in connections[trip]:\n",
    "                outflow += x[(trip, to_id)]\n",
    "        \n",
    "        model.addConstr(inflow == 1, f\"Trip_{trip}_must_be_served\")\n",
    "        model.addConstr(inflow == outflow, f\"Flow_conservation_{trip}\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    outflow_from_depot = gp.LinExpr()\n",
    "    if depot_id in connections:\n",
    "        for to_id in connections[depot_id]:\n",
    "            outflow_from_depot += x[(depot_id, to_id)]\n",
    "    \n",
    "    model.addConstr(outflow_from_depot <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set time limit and solver parameters\n",
    "    model.setParam('TimeLimit', 300)  # 5 minutes time limit\n",
    "    model.setParam('OutputFlag', 1)   # Display solver output\n",
    "    \n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        print(f\"Total cost: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        if depot_id in connections:\n",
    "            for to_id in connections[depot_id]:\n",
    "                if x[(depot_id, to_id)].x > 0.5:  # If this connection is used\n",
    "                    # Start a new vehicle schedule\n",
    "                    schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                    \n",
    "                    # Follow the path of this vehicle\n",
    "                    current_id = to_id\n",
    "                    while current_id != depot_id:\n",
    "                        # Add this trip to the schedule\n",
    "                        trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                        schedule.append({\n",
    "                            'type': 'trip',\n",
    "                            'id': current_id,\n",
    "                            'start_location': trip_info['start_location'],\n",
    "                            'end_location': trip_info['end_location'],\n",
    "                            'start_time': trip_info['scheduled_start_time'],\n",
    "                            'end_time': trip_info['scheduled_end_time'],\n",
    "                            'route_id': trip_info['route_id'],\n",
    "                            'direction_id': trip_info['direction_id']\n",
    "                        })\n",
    "                        \n",
    "                        # Find the next trip/depot\n",
    "                        next_id = None\n",
    "                        if current_id in connections:\n",
    "                            for possible_next in connections[current_id]:\n",
    "                                if x[(current_id, possible_next)].x > 0.5:\n",
    "                                    next_id = possible_next\n",
    "                                    break\n",
    "                        \n",
    "                        if next_id is None:\n",
    "                            print(f\"Warning: No next trip found for {current_id}\")\n",
    "                            break\n",
    "                            \n",
    "                        current_id = next_id\n",
    "                    \n",
    "                    # Close the schedule with return to depot\n",
    "                    schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                    \n",
    "                    # Add this schedule to the list\n",
    "                    vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation with Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_SetPartitioning\")\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = model.addVar(vtype=GRB.BINARY, name=f\"y_{i}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        obj += y[i] * schedule['cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        constr = gp.LinExpr()\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if trip in schedule['trips']:\n",
    "                constr += y[i]\n",
    "        model.addConstr(constr == 1, f\"Trip_{trip}_must_be_served\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    vehicles_constr = gp.LinExpr()\n",
    "    for i in range(len(feasible_schedules)):\n",
    "        vehicles_constr += y[i]\n",
    "    model.addConstr(vehicles_constr <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set time limit and solver parameters\n",
    "    model.setParam('TimeLimit', 300)  # 5 minutes time limit\n",
    "    model.setParam('OutputFlag', 1)   # Display solver output\n",
    "    \n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        print(f\"Total cost: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if y[i].x > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation using Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_SetPartitioning_LP\")\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = model.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"y_{i}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        obj += y[i] * schedule['cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        constr = gp.LinExpr()\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if trip in schedule['trips']:\n",
    "                constr += y[i]\n",
    "        model.addConstr(constr == 1, f\"Trip_{trip}_must_be_served\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    vehicles_constr = gp.LinExpr()\n",
    "    for i in range(len(feasible_schedules)):\n",
    "        vehicles_constr += y[i]\n",
    "    model.addConstr(vehicles_constr <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set solver parameters\n",
    "    model.setParam('OutputFlag', 0)  # Suppress solver output\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        print(f\"Set partitioning LP relaxation - Objective: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation using Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the Gurobi model for arc-flow\n",
    "    model = gp.Model(\"MDVSP_ArcFlow_LP\")\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = model.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"x_{from_id}_{to_id}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        obj += x[(from_id, to_id)] * conn['total_cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = gp.LinExpr()\n",
    "        outflow = gp.LinExpr()\n",
    "        \n",
    "        for from_id in connections:\n",
    "            if trip in connections[from_id]:\n",
    "                inflow += x[(from_id, trip)]\n",
    "        \n",
    "        if trip in connections:\n",
    "            for to_id in connections[trip]:\n",
    "                outflow += x[(trip, to_id)]\n",
    "        \n",
    "        model.addConstr(inflow == 1, f\"Trip_{trip}_must_be_served\")\n",
    "        model.addConstr(inflow == outflow, f\"Flow_conservation_{trip}\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    outflow_from_depot = gp.LinExpr()\n",
    "    if depot_id in connections:\n",
    "        for to_id in connections[depot_id]:\n",
    "            outflow_from_depot += x[(depot_id, to_id)]\n",
    "    \n",
    "    model.addConstr(outflow_from_depot <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set solver parameters\n",
    "    model.setParam('OutputFlag', 0)  # Suppress solver output\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        print(f\"Arc-flow LP relaxation - Objective: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_16h_20h.csv'\n",
    "    trip_nodes_output = 'route100_16h_20h_trip_nodes_gurobi.csv'\n",
    "    connections_output = 'route100_16h_20h_connections_gurobi.csv'\n",
    "    arc_flow_solution_output = 'route100_16h_20h_arc_flow_solution_gurobi.csv'\n",
    "    set_partitioning_solution_output = 'route100_16h_20h_set_partitioning_solution_gurobi.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8fd38-fcb1-411e-842c-d1b1a70a4ced",
   "metadata": {},
   "source": [
    "## c. 5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285b02e-9325-4f80-be57-b1b679135ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 1: Creating trip nodes ---\n",
      "Total records: 48\n",
      "Unique half_trip_ids: 24\n",
      "Unique stop_ids: [52711  8301  8302 52720]\n",
      "Unique time_point_ids: ['welst' 'elm']\n",
      "\n",
      "Created 24 trip nodes\n",
      "\n",
      "Sample trip nodes:\n",
      "   half_trip_id  route_id direction_id start_location end_location  \\\n",
      "0    65802625.0       100     Outbound          welst          elm   \n",
      "1    65802626.0       100      Inbound            elm        welst   \n",
      "2    65802627.0       100     Outbound          welst          elm   \n",
      "3    65802628.0       100      Inbound            elm        welst   \n",
      "4    65802629.0       100     Outbound          welst          elm   \n",
      "\n",
      "  scheduled_start_time  scheduled_end_time   actual_start_time  \\\n",
      "0  2025-04-29 15:00:00 2025-04-29 15:11:00 2025-04-29 15:06:11   \n",
      "1  2025-04-29 15:15:00 2025-04-29 15:26:00 2025-04-29 15:24:30   \n",
      "2  2025-04-29 15:30:00 2025-04-29 15:41:00 2025-04-29 15:38:30   \n",
      "3  2025-04-29 15:45:00 2025-04-29 15:57:00 2025-04-29 15:48:49   \n",
      "4  2025-04-29 16:00:00 2025-04-29 16:11:00 2025-04-29 16:06:48   \n",
      "\n",
      "      actual_end_time  \n",
      "0 2025-04-29 15:18:05  \n",
      "1 2025-04-29 15:36:31  \n",
      "2 2025-04-29 15:48:10  \n",
      "3 2025-04-29 16:00:03  \n",
      "4 2025-04-29 16:18:58  \n",
      "\n",
      "Trip nodes saved to route100_15h_20h_trip_nodes.csv\n",
      "\n",
      "--- STEP 2: Calculating connections and costs ---\n",
      "\n",
      "Created 324 connections\n",
      "\n",
      "Sample connections:\n",
      "           from_id       to_id from_type to_type    from_location to_location  \\\n",
      "0  fellsway_garage  65802625.0     depot    trip  fellsway_garage       welst   \n",
      "1  fellsway_garage  65802626.0     depot    trip  fellsway_garage         elm   \n",
      "2  fellsway_garage  65802627.0     depot    trip  fellsway_garage       welst   \n",
      "3  fellsway_garage  65802628.0     depot    trip  fellsway_garage         elm   \n",
      "4  fellsway_garage  65802629.0     depot    trip  fellsway_garage       welst   \n",
      "\n",
      "   distance_miles  travel_time_minutes  deadheading_cost  waiting_cost  \\\n",
      "0             2.0                 10.0             15.00           0.0   \n",
      "1             1.7                  8.5             12.75           0.0   \n",
      "2             2.0                 10.0             15.00           0.0   \n",
      "3             1.7                  8.5             12.75           0.0   \n",
      "4             2.0                 10.0             15.00           0.0   \n",
      "\n",
      "   delay_risk_cost  total_cost  waiting_time_minutes  \n",
      "0              0.0       15.00                   NaN  \n",
      "1              0.0       12.75                   NaN  \n",
      "2              0.0       15.00                   NaN  \n",
      "3              0.0       12.75                   NaN  \n",
      "4              0.0       15.00                   NaN  \n",
      "\n",
      "Connections saved to route100_15h_20h_connections.csv\n",
      "\n",
      "--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\n",
      "Analyzing LP relaxation of arc-flow formulation with Gurobi...\n",
      "Arc-flow LP relaxation - Status: 2\n",
      "Arc-flow LP relaxation - Objective: 378.29999999999995\n",
      "Solution time: 0.03 seconds\n",
      "\n",
      "--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\n",
      "Analyzing LP relaxation of set partitioning formulation with Gurobi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_19708/4176640161.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_19708/4176640161.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_19708/4176640161.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
      "/var/folders/v8/1793d44577q9lqgx_01s8skm0000gn/T/ipykernel_19708/4176640161.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 16777215 feasible schedules\n",
      "Set partitioning LP relaxation - Status: 11\n",
      "Solution time: 1524.13 seconds\n",
      "\n",
      "--- STEP 5: Solving with arc-flow formulation ---\n",
      "Solving MDVSP using arc-flow formulation with Gurobi...\n",
      "Set parameter TimeLimit to value 300\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 49 rows, 324 columns and 924 nonzeros\n",
      "Model fingerprint: 0x17dbffab\n",
      "Variable types: 0 continuous, 324 integer (324 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [7e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 701.6166667\n",
      "Presolve removed 12 rows and 58 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 37 rows, 266 columns, 510 nonzeros\n",
      "Found heuristic solution: objective 446.3833333\n",
      "Variable types: 0 continuous, 266 integer (266 binary)\n",
      "\n",
      "Root relaxation: objective 3.783000e+02, 27 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "Interrupt request received\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     378.3000000  378.30000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (27 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 378.3 446.383 701.617 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.783000000000e+02, best bound 3.783000000000e+02, gap 0.0000%\n",
      "Status: 2\n",
      "Total cost: 378.29999999999995\n",
      "Solution time: 0.10 seconds\n",
      "\n",
      "Sample arc-flow solution:\n",
      "   vehicle_id  stop_num   type               id         location  \\\n",
      "0           1         1  depot  fellsway_garage  fellsway_garage   \n",
      "1           1         2   trip       65802625.0              NaN   \n",
      "2           1         3   trip       65802626.0              NaN   \n",
      "3           1         4   trip       65802627.0              NaN   \n",
      "4           1         5   trip       65802628.0              NaN   \n",
      "\n",
      "  start_location end_location          start_time            end_time  \\\n",
      "0            NaN          NaN                 NaT                 NaT   \n",
      "1          welst          elm 2025-04-29 15:00:00 2025-04-29 15:11:00   \n",
      "2            elm        welst 2025-04-29 15:15:00 2025-04-29 15:26:00   \n",
      "3          welst          elm 2025-04-29 15:30:00 2025-04-29 15:41:00   \n",
      "4            elm        welst 2025-04-29 15:45:00 2025-04-29 15:57:00   \n",
      "\n",
      "   route_id direction_id  \n",
      "0       NaN          NaN  \n",
      "1     100.0     Outbound  \n",
      "2     100.0      Inbound  \n",
      "3     100.0     Outbound  \n",
      "4     100.0      Inbound  \n",
      "\n",
      "Arc-flow solution saved to route100_15h_20h_arc_flow_solution.csv\n",
      "\n",
      "--- STEP 6: Solving with set partitioning formulation ---\n",
      "Solving MDVSP using set partitioning formulation with Gurobi...\n",
      "Generating feasible vehicle schedules...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "\n",
    "# Define bus operation parameters\n",
    "BUS_PARAMS = {\n",
    "    'avg_speed_mph': 12,  # Average bus speed in mph\n",
    "    'cost_per_mile': 2.5,  # Operating cost per mile\n",
    "    'cost_per_minute': 1.0,  # Cost per minute of operation\n",
    "    'waiting_cost_factor': 0.5,  # Cost factor for waiting time\n",
    "    'delay_risk_factor': 2.0  # Cost factor for delay risk\n",
    "}\n",
    "\n",
    "# Define the depot\n",
    "DEPOT_ID = 'fellsway_garage'\n",
    "\n",
    "# Define distances from Google Maps screenshots (in miles)\n",
    "DISTANCES = {\n",
    "    'depot_to_welst': 2.0,  # Fellsway Garage to Wellington St\n",
    "    'depot_to_elmst': 1.4,  # Fellsway Garage to Elm St\n",
    "    'welst_to_depot': 2.0,  # Wellington St to Fellsway Garage\n",
    "    'elmst_to_depot': 1.4,  # Elm St to Fellsway Garage\n",
    "    'elmst_to_welst': 1.5,  # Estimated distance between stops\n",
    "    'welst_to_elmst': 1.5   # Estimated distance between stops\n",
    "}\n",
    "\n",
    "def calculate_travel_time(distance, speed=BUS_PARAMS['avg_speed_mph']):\n",
    "    \"\"\"Calculate travel time based on distance and speed\"\"\"\n",
    "    return (distance / speed) * 60\n",
    "\n",
    "def create_trip_nodes(csv_path):\n",
    "    \"\"\"Create trip nodes from the filtered CSV data\"\"\"\n",
    "    # Read the filtered data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print data summary\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique half_trip_ids: {df['half_trip_id'].nunique()}\")\n",
    "    print(f\"Unique stop_ids: {df['stop_id'].unique()}\")\n",
    "    print(f\"Unique time_point_ids: {df['time_point_id'].unique()}\")\n",
    "    \n",
    "    # Map time_point_ids to our location codes\n",
    "    location_map = {\n",
    "        'elmst': 'elmst',\n",
    "        'welst': 'welst'\n",
    "    }\n",
    "    \n",
    "    # Group by half_trip_id\n",
    "    trips = []\n",
    "    \n",
    "    # For each half_trip_id, find its startpoint and endpoint\n",
    "    for half_trip_id, group in df.groupby('half_trip_id'):\n",
    "        startpoints = group[group['point_type'] == 'Startpoint']\n",
    "        endpoints = group[group['point_type'] == 'Endpoint']\n",
    "        \n",
    "        if not startpoints.empty and not endpoints.empty:\n",
    "            # Get start and end locations\n",
    "            start_time_point = startpoints['time_point_id'].iloc[0]\n",
    "            end_time_point = endpoints['time_point_id'].iloc[0]\n",
    "            \n",
    "            # Map to our location codes\n",
    "            start_location = location_map.get(start_time_point, start_time_point)\n",
    "            end_location = location_map.get(end_time_point, end_time_point)\n",
    "            \n",
    "            trip = {\n",
    "                'half_trip_id': half_trip_id,\n",
    "                'route_id': group['route_id'].iloc[0],\n",
    "                'direction_id': group['direction_id'].iloc[0],\n",
    "                'start_location': start_location,\n",
    "                'end_location': end_location,\n",
    "                'scheduled_start_time': startpoints['scheduled'].iloc[0],\n",
    "                'scheduled_end_time': endpoints['scheduled'].iloc[0],\n",
    "                'actual_start_time': startpoints['actual'].iloc[0],\n",
    "                'actual_end_time': endpoints['actual'].iloc[0]\n",
    "            }\n",
    "            trips.append(trip)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    trips_df = pd.DataFrame(trips)\n",
    "    \n",
    "    # Parse datetime strings\n",
    "    for col in ['scheduled_start_time', 'scheduled_end_time', 'actual_start_time', 'actual_end_time']:\n",
    "        if col in trips_df.columns:\n",
    "            # Convert times to datetime objects\n",
    "            trips_df[col] = pd.to_datetime(trips_df[col], errors='coerce')\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "def calculate_costs(trips_df, depot_id=DEPOT_ID):\n",
    "    \"\"\"\n",
    "    Calculate costs between trips and depot connections using distances from Google Maps\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        depot_id: ID of the depot\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with trip-to-trip costs and depot connections\n",
    "    \"\"\"\n",
    "    # Get parameters\n",
    "    cost_per_mile = BUS_PARAMS['cost_per_mile']\n",
    "    cost_per_minute = BUS_PARAMS['cost_per_minute']\n",
    "    waiting_cost_factor = BUS_PARAMS['waiting_cost_factor']\n",
    "    delay_risk_factor = BUS_PARAMS['delay_risk_factor']\n",
    "    \n",
    "    # Create empty lists to store connections\n",
    "    connections = []\n",
    "    \n",
    "    # Add depot to start connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from depot to this trip's start location\n",
    "        if trip['start_location'] == 'welst':\n",
    "            distance = DISTANCES['depot_to_welst']\n",
    "        elif trip['start_location'] == 'elmst':\n",
    "            distance = DISTANCES['depot_to_elmst']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['depot_to_welst'] + DISTANCES['depot_to_elmst']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': depot_id,\n",
    "            'to_id': trip['half_trip_id'],\n",
    "            'from_type': 'depot',\n",
    "            'to_type': 'trip',\n",
    "            'from_location': depot_id,\n",
    "            'to_location': trip['start_location'],\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add end to depot connections\n",
    "    for _, trip in trips_df.iterrows():\n",
    "        # Get distance from this trip's end location to depot\n",
    "        if trip['end_location'] == 'welst':\n",
    "            distance = DISTANCES['welst_to_depot']\n",
    "        elif trip['end_location'] == 'elmst':\n",
    "            distance = DISTANCES['elmst_to_depot']\n",
    "        else:\n",
    "            # Use average distance for any other locations\n",
    "            distance = (DISTANCES['welst_to_depot'] + DISTANCES['elmst_to_depot']) / 2\n",
    "            \n",
    "        # Calculate travel time\n",
    "        travel_time = calculate_travel_time(distance)\n",
    "        \n",
    "        # Calculate costs\n",
    "        deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "        \n",
    "        connection = {\n",
    "            'from_id': trip['half_trip_id'],\n",
    "            'to_id': depot_id,\n",
    "            'from_type': 'trip',\n",
    "            'to_type': 'depot',\n",
    "            'from_location': trip['end_location'],\n",
    "            'to_location': depot_id,\n",
    "            'distance_miles': distance,\n",
    "            'travel_time_minutes': travel_time,\n",
    "            'deadheading_cost': deadheading_cost,\n",
    "            'waiting_cost': 0,\n",
    "            'delay_risk_cost': 0,\n",
    "            'total_cost': deadheading_cost\n",
    "        }\n",
    "        connections.append(connection)\n",
    "    \n",
    "    # Add trip-to-trip connections\n",
    "    for i, trip_i in trips_df.iterrows():\n",
    "        for j, trip_j in trips_df.iterrows():\n",
    "            # Skip same trip\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            # Check if trip_j can follow trip_i (time compatibility)\n",
    "            if pd.isnull(trip_i['scheduled_end_time']) or pd.isnull(trip_j['scheduled_start_time']):\n",
    "                continue\n",
    "            \n",
    "            # Get distance between end of trip_i and start of trip_j\n",
    "            from_loc = trip_i['end_location']\n",
    "            to_loc = trip_j['start_location']\n",
    "            \n",
    "            if from_loc == 'elmst' and to_loc == 'welst':\n",
    "                distance = DISTANCES['elmst_to_welst']\n",
    "            elif from_loc == 'welst' and to_loc == 'elmst':\n",
    "                distance = DISTANCES['welst_to_elmst']\n",
    "            elif from_loc == to_loc:\n",
    "                distance = 0.1  # Short distance if same location\n",
    "            else:\n",
    "                # Use average for any other combinations\n",
    "                distance = (DISTANCES['elmst_to_welst'] + DISTANCES['welst_to_elmst']) / 2\n",
    "            \n",
    "            # Calculate travel time\n",
    "            travel_time = calculate_travel_time(distance)\n",
    "            \n",
    "            # Calculate earliest possible arrival time at start of trip_j\n",
    "            earliest_arrival = trip_i['scheduled_end_time'] + timedelta(minutes=travel_time)\n",
    "            \n",
    "            # Check if trip_j can be served after trip_i\n",
    "            if earliest_arrival <= trip_j['scheduled_start_time']:\n",
    "                # Calculate waiting time\n",
    "                waiting_time = (trip_j['scheduled_start_time'] - earliest_arrival).total_seconds() / 60\n",
    "                \n",
    "                # Calculate delay risk (if trip_i has history of delays)\n",
    "                if not pd.isnull(trip_i['actual_end_time']) and not pd.isnull(trip_i['scheduled_end_time']):\n",
    "                    delay = (trip_i['actual_end_time'] - trip_i['scheduled_end_time']).total_seconds() / 60\n",
    "                    delay_risk = max(0, delay)\n",
    "                else:\n",
    "                    delay_risk = 0\n",
    "                \n",
    "                # Calculate costs\n",
    "                deadheading_cost = distance * cost_per_mile + travel_time * cost_per_minute\n",
    "                waiting_cost = waiting_time * waiting_cost_factor * cost_per_minute\n",
    "                delay_risk_cost = delay_risk * delay_risk_factor * cost_per_minute\n",
    "                total_cost = deadheading_cost + waiting_cost + delay_risk_cost\n",
    "                \n",
    "                connection = {\n",
    "                    'from_id': trip_i['half_trip_id'],\n",
    "                    'to_id': trip_j['half_trip_id'],\n",
    "                    'from_type': 'trip',\n",
    "                    'to_type': 'trip',\n",
    "                    'from_location': trip_i['end_location'],\n",
    "                    'to_location': trip_j['start_location'],\n",
    "                    'distance_miles': distance,\n",
    "                    'travel_time_minutes': travel_time,\n",
    "                    'waiting_time_minutes': waiting_time,\n",
    "                    'deadheading_cost': deadheading_cost,\n",
    "                    'waiting_cost': waiting_cost,\n",
    "                    'delay_risk_cost': delay_risk_cost,\n",
    "                    'total_cost': total_cost\n",
    "                }\n",
    "                connections.append(connection)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    connections_df = pd.DataFrame(connections)\n",
    "    return connections_df\n",
    "\n",
    "def solve_arc_flow_mdvsp(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the arc-flow formulation with Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using arc-flow formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_ArcFlow\")\n",
    "    \n",
    "    # Create variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        # Create binary variable for this connection\n",
    "        x[(from_id, to_id)] = model.addVar(vtype=GRB.BINARY, name=f\"x_{from_id}_{to_id}\")\n",
    "    \n",
    "    # Update the model to include new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        obj += x[(from_id, to_id)] * conn['total_cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = gp.LinExpr()\n",
    "        outflow = gp.LinExpr()\n",
    "        \n",
    "        for from_id in connections:\n",
    "            if trip in connections[from_id]:\n",
    "                inflow += x[(from_id, trip)]\n",
    "        \n",
    "        if trip in connections:\n",
    "            for to_id in connections[trip]:\n",
    "                outflow += x[(trip, to_id)]\n",
    "        \n",
    "        model.addConstr(inflow == 1, f\"Trip_{trip}_must_be_served\")\n",
    "        model.addConstr(inflow == outflow, f\"Flow_conservation_{trip}\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    outflow_from_depot = gp.LinExpr()\n",
    "    if depot_id in connections:\n",
    "        for to_id in connections[depot_id]:\n",
    "            outflow_from_depot += x[(depot_id, to_id)]\n",
    "    \n",
    "    model.addConstr(outflow_from_depot <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set time limit and solver parameters\n",
    "    model.setParam('TimeLimit', 300)  # 5 minutes time limit\n",
    "    model.setParam('OutputFlag', 1)   # Display solver output\n",
    "    \n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        print(f\"Total cost: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        # Create a list to store vehicle schedules\n",
    "        vehicle_schedules = []\n",
    "        \n",
    "        # Start with connections from depot\n",
    "        if depot_id in connections:\n",
    "            for to_id in connections[depot_id]:\n",
    "                if x[(depot_id, to_id)].x > 0.5:  # If this connection is used\n",
    "                    # Start a new vehicle schedule\n",
    "                    schedule = [{'type': 'depot', 'id': depot_id, 'location': depot_id}]\n",
    "                    \n",
    "                    # Follow the path of this vehicle\n",
    "                    current_id = to_id\n",
    "                    while current_id != depot_id:\n",
    "                        # Add this trip to the schedule\n",
    "                        trip_info = trips_df[trips_df['half_trip_id'] == current_id].iloc[0].to_dict()\n",
    "                        schedule.append({\n",
    "                            'type': 'trip',\n",
    "                            'id': current_id,\n",
    "                            'start_location': trip_info['start_location'],\n",
    "                            'end_location': trip_info['end_location'],\n",
    "                            'start_time': trip_info['scheduled_start_time'],\n",
    "                            'end_time': trip_info['scheduled_end_time'],\n",
    "                            'route_id': trip_info['route_id'],\n",
    "                            'direction_id': trip_info['direction_id']\n",
    "                        })\n",
    "                        \n",
    "                        # Find the next trip/depot\n",
    "                        next_id = None\n",
    "                        if current_id in connections:\n",
    "                            for possible_next in connections[current_id]:\n",
    "                                if x[(current_id, possible_next)].x > 0.5:\n",
    "                                    next_id = possible_next\n",
    "                                    break\n",
    "                        \n",
    "                        if next_id is None:\n",
    "                            print(f\"Warning: No next trip found for {current_id}\")\n",
    "                            break\n",
    "                            \n",
    "                        current_id = next_id\n",
    "                    \n",
    "                    # Close the schedule with return to depot\n",
    "                    schedule.append({'type': 'depot', 'id': depot_id, 'location': depot_id})\n",
    "                    \n",
    "                    # Add this schedule to the list\n",
    "                    vehicle_schedules.append(schedule)\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        schedule_rows = []\n",
    "        for vehicle_id, schedule in enumerate(vehicle_schedules):\n",
    "            for stop_num, stop in enumerate(schedule):\n",
    "                row = {\n",
    "                    'vehicle_id': vehicle_id + 1,\n",
    "                    'stop_num': stop_num + 1,\n",
    "                    'type': stop['type'],\n",
    "                    'id': stop['id']\n",
    "                }\n",
    "                \n",
    "                # Add location information\n",
    "                if 'location' in stop:\n",
    "                    row['location'] = stop['location']\n",
    "                \n",
    "                # Add trip details if this is a trip\n",
    "                if stop['type'] == 'trip':\n",
    "                    row.update({\n",
    "                        'start_location': stop['start_location'],\n",
    "                        'end_location': stop['end_location'],\n",
    "                        'start_time': stop['start_time'],\n",
    "                        'end_time': stop['end_time'],\n",
    "                        'route_id': stop['route_id'],\n",
    "                        'direction_id': stop['direction_id']\n",
    "                    })\n",
    "                \n",
    "                schedule_rows.append(row)\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def solve_set_partitioning_mdvsp(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Solve the MDVSP using the set partitioning formulation with Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "        \n",
    "    Returns:\n",
    "        Solution DataFrame with vehicle schedules\n",
    "    \"\"\"\n",
    "    print(\"Solving MDVSP using set partitioning formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules (paths from depot to depot)\n",
    "    print(\"Generating feasible vehicle schedules...\")\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost,\n",
    "                'path': current_path.copy()  # Keep full path for reference\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_SetPartitioning\")\n",
    "    \n",
    "    # Create variables - one for each feasible schedule\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = model.addVar(vtype=GRB.BINARY, name=f\"y_{i}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        obj += y[i] * schedule['cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        constr = gp.LinExpr()\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if trip in schedule['trips']:\n",
    "                constr += y[i]\n",
    "        model.addConstr(constr == 1, f\"Trip_{trip}_must_be_served\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    vehicles_constr = gp.LinExpr()\n",
    "    for i in range(len(feasible_schedules)):\n",
    "        vehicles_constr += y[i]\n",
    "    model.addConstr(vehicles_constr <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set time limit and solver parameters\n",
    "    model.setParam('TimeLimit', 300)  # 5 minutes time limit\n",
    "    model.setParam('OutputFlag', 1)   # Display solver output\n",
    "    \n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        print(f\"Total cost: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract solution\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "        # Create a list to store vehicle schedules\n",
    "        schedule_rows = []\n",
    "        \n",
    "        # Process each selected schedule\n",
    "        vehicle_id = 1\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if y[i].x > 0.5:  # If this schedule is used\n",
    "                path = schedule['path']\n",
    "                \n",
    "                # Add depot departure\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': 1,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                # Add each trip in the schedule\n",
    "                for stop_num, trip_id in enumerate(schedule['trips']):\n",
    "                    # Get trip details\n",
    "                    trip_info = trips_df[trips_df['half_trip_id'] == trip_id].iloc[0].to_dict()\n",
    "                    \n",
    "                    schedule_rows.append({\n",
    "                        'vehicle_id': vehicle_id,\n",
    "                        'stop_num': stop_num + 2,\n",
    "                        'type': 'trip',\n",
    "                        'id': trip_id,\n",
    "                        'start_location': trip_info['start_location'],\n",
    "                        'end_location': trip_info['end_location'],\n",
    "                        'start_time': trip_info['scheduled_start_time'],\n",
    "                        'end_time': trip_info['scheduled_end_time'],\n",
    "                        'route_id': trip_info['route_id'],\n",
    "                        'direction_id': trip_info['direction_id']\n",
    "                    })\n",
    "                \n",
    "                # Add depot return\n",
    "                schedule_rows.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'stop_num': len(schedule['trips']) + 2,\n",
    "                    'type': 'depot',\n",
    "                    'id': depot_id,\n",
    "                    'location': depot_id\n",
    "                })\n",
    "                \n",
    "                vehicle_id += 1\n",
    "        \n",
    "        schedules_df = pd.DataFrame(schedule_rows)\n",
    "        return schedules_df\n",
    "    else:\n",
    "        print(\"No optimal solution found.\")\n",
    "        return None\n",
    "\n",
    "def analyze_lp_relaxation_set_partitioning(trips_df, connections_df, depot_id='fellsway_garage', max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of set partitioning formulation using Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of set partitioning formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a graph representation for the network\n",
    "    graph = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        cost = conn['total_cost']\n",
    "        \n",
    "        if from_id not in graph:\n",
    "            graph[from_id] = {}\n",
    "        graph[from_id][to_id] = cost\n",
    "    \n",
    "    # Generate all feasible vehicle schedules\n",
    "    feasible_schedules = []\n",
    "    \n",
    "    # Use a recursive function to find all paths from depot to depot\n",
    "    def find_paths(current_path, visited_trips, current_cost):\n",
    "        current_node = current_path[-1]\n",
    "        \n",
    "        # If we've returned to the depot and visited at least one trip, we have a feasible schedule\n",
    "        if current_node == depot_id and len(current_path) > 2:\n",
    "            # Extract just the trip IDs (exclude depot at start and end)\n",
    "            trip_ids = [node for node in current_path[1:-1]]\n",
    "            feasible_schedules.append({\n",
    "                'trips': trip_ids,\n",
    "                'cost': current_cost\n",
    "            })\n",
    "            return\n",
    "        \n",
    "        # If we're at the maximum path length, stop recursion\n",
    "        if len(current_path) > len(trips) + 2:\n",
    "            return\n",
    "        \n",
    "        # Try all possible next nodes\n",
    "        if current_node in graph:\n",
    "            for next_node, edge_cost in graph[current_node].items():\n",
    "                # Skip if this trip has already been visited\n",
    "                if next_node in trips and next_node in visited_trips:\n",
    "                    continue\n",
    "                \n",
    "                # Add this node to the path\n",
    "                new_path = current_path + [next_node]\n",
    "                new_visited = visited_trips.copy()\n",
    "                if next_node in trips:\n",
    "                    new_visited.add(next_node)\n",
    "                \n",
    "                # Continue recursion\n",
    "                find_paths(new_path, new_visited, current_cost + edge_cost)\n",
    "    \n",
    "    # Start with paths from the depot\n",
    "    find_paths([depot_id], set(), 0)\n",
    "    \n",
    "    print(f\"Generated {len(feasible_schedules)} feasible schedules\")\n",
    "    \n",
    "    # Create the Gurobi model\n",
    "    model = gp.Model(\"MDVSP_SetPartitioning_LP\")\n",
    "    \n",
    "    # Create continuous variables (for LP relaxation)\n",
    "    y = {}\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        y[i] = model.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"y_{i}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for i, schedule in enumerate(feasible_schedules):\n",
    "        obj += y[i] * schedule['cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Each trip must be covered exactly once\n",
    "    for trip in trips:\n",
    "        constr = gp.LinExpr()\n",
    "        for i, schedule in enumerate(feasible_schedules):\n",
    "            if trip in schedule['trips']:\n",
    "                constr += y[i]\n",
    "        model.addConstr(constr == 1, f\"Trip_{trip}_must_be_served\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    vehicles_constr = gp.LinExpr()\n",
    "    for i in range(len(feasible_schedules)):\n",
    "        vehicles_constr += y[i]\n",
    "    model.addConstr(vehicles_constr <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set solver parameters\n",
    "    model.setParam('OutputFlag', 0)  # Suppress solver output\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Set partitioning LP relaxation - Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        print(f\"Set partitioning LP relaxation - Objective: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def analyze_lp_relaxation(trips_df, connections_df, depot_id=DEPOT_ID, max_vehicles=10):\n",
    "    \"\"\"\n",
    "    Analyze the LP relaxation of arc-flow formulation using Gurobi\n",
    "    \n",
    "    Args:\n",
    "        trips_df: DataFrame of trip nodes\n",
    "        connections_df: DataFrame of connections between trips\n",
    "        depot_id: ID of the depot\n",
    "        max_vehicles: Maximum number of vehicles available\n",
    "    \"\"\"\n",
    "    print(\"Analyzing LP relaxation of arc-flow formulation with Gurobi...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of all trips\n",
    "    trips = trips_df['half_trip_id'].tolist()\n",
    "    \n",
    "    # Create a dictionary to store connections\n",
    "    connections = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        total_cost = conn['total_cost']\n",
    "        \n",
    "        # Add connection to the dictionary\n",
    "        if from_id not in connections:\n",
    "            connections[from_id] = {}\n",
    "        connections[from_id][to_id] = total_cost\n",
    "    \n",
    "    # Create the Gurobi model for arc-flow\n",
    "    model = gp.Model(\"MDVSP_ArcFlow_LP\")\n",
    "    \n",
    "    # Create continuous variables\n",
    "    x = {}\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        \n",
    "        \n",
    "        # Create continuous variable for this connection\n",
    "        x[(from_id, to_id)] = model.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"x_{from_id}_{to_id}\")\n",
    "    \n",
    "    # Update model to incorporate new variables\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: minimize total cost\n",
    "    obj = gp.LinExpr()\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        from_id = conn['from_id']\n",
    "        to_id = conn['to_id']\n",
    "        obj += x[(from_id, to_id)] * conn['total_cost']\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraint 1: Flow conservation for trips\n",
    "    for trip in trips:\n",
    "        # Inflow equals outflow for each trip\n",
    "        inflow = gp.LinExpr()\n",
    "        outflow = gp.LinExpr()\n",
    "        \n",
    "        for from_id in connections:\n",
    "            if trip in connections[from_id]:\n",
    "                inflow += x[(from_id, trip)]\n",
    "        \n",
    "        if trip in connections:\n",
    "            for to_id in connections[trip]:\n",
    "                outflow += x[(trip, to_id)]\n",
    "        \n",
    "        model.addConstr(inflow == 1, f\"Trip_{trip}_must_be_served\")\n",
    "        model.addConstr(inflow == outflow, f\"Flow_conservation_{trip}\")\n",
    "    \n",
    "    # Constraint 2: Maximum number of vehicles\n",
    "    outflow_from_depot = gp.LinExpr()\n",
    "    if depot_id in connections:\n",
    "        for to_id in connections[depot_id]:\n",
    "            outflow_from_depot += x[(depot_id, to_id)]\n",
    "    \n",
    "    model.addConstr(outflow_from_depot <= max_vehicles, \"Max_vehicles\")\n",
    "    \n",
    "    # Set solver parameters\n",
    "    model.setParam('OutputFlag', 0)  # Suppress solver output\n",
    "    \n",
    "    # Solve the LP relaxation\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    solution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Arc-flow LP relaxation - Status: {model.status}\")\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        print(f\"Arc-flow LP relaxation - Objective: {model.objVal}\")\n",
    "    print(f\"Solution time: {solution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    # Input and output paths\n",
    "    input_csv = 'filtered_route100_15h_20h.csv'\n",
    "    trip_nodes_output = 'route100_15h_20h_trip_nodes_gurobi.csv'\n",
    "    connections_output = 'route100_15h_20h_connections_gurobi.csv'\n",
    "    arc_flow_solution_output = 'route100_15h_20h_arc_flow_solution_gurobi.csv'\n",
    "    set_partitioning_solution_output = 'route100_15h_20h_set_partitioning_solution_gurobi.csv'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create trip nodes\n",
    "        print(\"\\n--- STEP 1: Creating trip nodes ---\")\n",
    "        trips_df = create_trip_nodes(input_csv)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(trips_df)} trip nodes\")\n",
    "        if not trips_df.empty:\n",
    "            print(\"\\nSample trip nodes:\")\n",
    "            print(trips_df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            trips_df.to_csv(trip_nodes_output, index=False)\n",
    "            print(f\"\\nTrip nodes saved to {trip_nodes_output}\")\n",
    "        \n",
    "        # Step 2: Calculate connections and costs\n",
    "        print(\"\\n--- STEP 2: Calculating connections and costs ---\")\n",
    "        connections_df = calculate_costs(trips_df)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nCreated {len(connections_df)} connections\")\n",
    "        print(\"\\nSample connections:\")\n",
    "        print(connections_df.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        connections_df.to_csv(connections_output, index=False)\n",
    "        print(f\"\\nConnections saved to {connections_output}\")\n",
    "        \n",
    "        # Step 3: Analyze LP relaxation of arc-flow formulation\n",
    "        print(\"\\n--- STEP 3: Analyzing LP relaxation of arc-flow formulation ---\")\n",
    "        analyze_lp_relaxation(trips_df, connections_df)\n",
    "        \n",
    "        # Step 4: Analyze LP relaxation of set partitioning formulation\n",
    "        print(\"\\n--- STEP 4: Analyzing LP relaxation of set partitioning formulation ---\")\n",
    "        analyze_lp_relaxation_set_partitioning(trips_df, connections_df)\n",
    "        \n",
    "        # Step 5: Solve using arc-flow formulation\n",
    "        print(\"\\n--- STEP 5: Solving with arc-flow formulation ---\")\n",
    "        arc_flow_solution = solve_arc_flow_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if arc_flow_solution is not None:\n",
    "            print(\"\\nSample arc-flow solution:\")\n",
    "            print(arc_flow_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            arc_flow_solution.to_csv(arc_flow_solution_output, index=False)\n",
    "            print(f\"\\nArc-flow solution saved to {arc_flow_solution_output}\")\n",
    "        \n",
    "        # Step 6: Solve using set partitioning formulation\n",
    "        print(\"\\n--- STEP 6: Solving with set partitioning formulation ---\")\n",
    "        set_partitioning_solution = solve_set_partitioning_mdvsp(trips_df, connections_df)\n",
    "        \n",
    "        if set_partitioning_solution is not None:\n",
    "            print(\"\\nSample set partitioning solution:\")\n",
    "            print(set_partitioning_solution.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            set_partitioning_solution.to_csv(set_partitioning_solution_output, index=False)\n",
    "            print(f\"\\nSet partitioning solution saved to {set_partitioning_solution_output}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3cc99-8efb-4b68-a85b-117fa0d313c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0dd03-d311-458c-b98c-01e1aa053abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4a004-4c65-4754-a97d-4cdfa64b96db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52abaef-51b2-40fe-af2f-432b9143322a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
